{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":7566468,"sourceType":"datasetVersion","datasetId":4050072}],"dockerImageVersionId":30529,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install --upgrade transformers datasets sentencepiece peft pandas pyarrow -q\n!pip install torch~=2.1.0 --index-url https://download.pytorch.org/whl/cpu -q # Updating torch since we need the latest version\n!pip install torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html -q\n!pip uninstall tensorflow -y # If we don't do this, TF will take over TPU and cause permission error for PT\n!cp /kaggle/input/utils-xla/spmd_util.py . # From this repo: https://github.com/HeegyuKim/torch-xla-SPMD","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":121.512757,"end_time":"2023-11-04T12:34:07.401258","exception":false,"start_time":"2023-11-04T12:32:05.888501","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport datasets\nimport torch.optim as optim\nimport torch_xla.debug.profiler as xp\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp # We also import mp modules if we wanna use that for some reason\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.test.test_utils as test_utils\nimport torch\nimport torch.nn as nn\nimport re\nimport torch_xla.experimental.xla_sharding as xs\nimport torch_xla.core.xla_model as xm\nfrom transformers import (\n    GPTNeoXConfig, T5Config, LlamaConfig, AutoTokenizer, AutoModelForCausalLM, MistralConfig, Qwen2Config, GPT2Config, DataCollatorWithPadding, AutoConfig, AutoModelForSequenceClassification\n) # You can use any of models with those configs (even flan T5 xxl!). Other models are not supported.\n\nfrom transformers import logging as hf_logging\nimport torch.nn.functional as F\nimport torch_xla.runtime as xr\n\nxr.use_spmd()\n\nimport torch_xla.experimental.xla_sharding as xs # \"experimental\" prefix always means you're gonna have a good time LMAO\nfrom torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor\nfrom torch_xla.experimental.xla_sharding import Mesh\n\nfrom peft import LoraConfig, TaskType, get_peft_model # If we wanna use peft. Quantazation requiers GPU though. You'll have to download already quantazed models\nfrom spmd_util import partition_module                # You could experiment with using already quantazed models like 4bit/Llama-2-7b-Chat-GPTQ if you're feeling funny\nfrom datasets import Dataset, load_dataset, concatenate_datasets\nfrom dataclasses import dataclass\nfrom tqdm import tqdm\n\nimport transformers\nimport datasets\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom torch.utils.data import Dataset as TorchDataset\nimport torch.utils\ntry:\n    !export USE_TORCH=True #If we don't do this, transformers will seemingly bork the session upon import. Really weird error.\n    os.environ[\"PJRT_DEVICE\"] = \"TPU\"\n    os.environ.pop('TPU_PROCESS_ADDRESSES')\n    os.environ.pop('CLOUD_TPU_TASK_ID')\n    hf_logging.set_verbosity_error() # It can still display warnings which is a bit annoying but whatever\nexcept:\n    pass\n\n\nMAX_INPUT=2048\nMODEL = \"mistralai/Mistral-7B-v0.1\" #You should be able to use 7B model with no changes! There should be enough HBM\nSAVED_MODEL = \"Locutusque/Hercules-2.0-Mistral-7B\"","metadata":{"papermill":{"duration":13.608021,"end_time":"2023-11-04T12:34:21.013846","exception":false,"start_time":"2023-11-04T12:34:07.405825","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConversationDataset(TorchDataset):\n    def __init__(self, tokenizer, max_length=512, dataset=None):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        messages = self.dataset[idx][\"conversations\"]\n        text = \"\"\n        for message in messages:\n            role = message[\"from\"]\n            if role == \"system\":\n                text += f\"<|im_start|>system\\n{message['value']}<|im_end|>\\n\"\n            if role == \"human\":\n                text += f\"<|im_start|>user\\n{message['value']}<|im_end|>\\n\"\n            if role == \"function-call\":\n                text += f\"<|im_start|>call\\n{message['value']}<|im_end|>\\n\"\n            if role == \"function-response\":\n                text += f\"<|im_start|>function\\n{message['value']}<|im_end|>\\n\"\n            if role ==\"gpt\":\n                text += f\"<|im_start|>assistant\\n{message['value']}{self.tokenizer.eos_token}\"\n        input_ids = self.tokenizer(text, add_special_tokens=True, max_length=self.max_length, truncation=True, padding=\"max_length\", return_attention_mask=True, return_tensors=\"pt\")\n        return {\n            \"input_ids\": input_ids[\"input_ids\"].squeeze(0),\n            \"labels\": input_ids[\"input_ids\"].squeeze(0),\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL, token=\"\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"papermill":{"duration":0.547357,"end_time":"2023-11-04T12:34:26.034497","exception":false,"start_time":"2023-11-04T12:34:25.48714","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = load_dataset(\"Locutusque/hercules-v2.0\", split=\"train[:100000]\", token=\"\")\nval = load_dataset('Locutusque/hercules-v2.0', split=\"train[:100]\", token=\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(MODEL, torch_dtype=torch.bfloat16, token=\"\")","metadata":{"papermill":{"duration":300.034782,"end_time":"2023-11-04T12:40:23.192281","exception":false,"start_time":"2023-11-04T12:35:23.157499","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FLAGS = {'MAX_INPUT': 512,\n         'LOGGING_STEPS': 1,\n         'NUM_EPOCHS': 1,\n         'BATCH_SIZE': 8, #Making batch_size lower then 8 will result in slower training, but will allow for larger models\\context. Fortunately, we have 128GBs. Setting higher batch_size doesn't seem to improve time.\n          'NUM_STEPS': len(train_data)} ","metadata":{"papermill":{"duration":0.027467,"end_time":"2023-11-04T12:40:23.239228","exception":false,"start_time":"2023-11-04T12:40:23.211761","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = ConversationDataset(tokenizer, dataset=train_data, max_length=512)\nval = ConversationDataset(tokenizer, dataset=val)\ntraining_loader = torch.utils.data.DataLoader(train_data, batch_size=FLAGS[\"BATCH_SIZE\"], shuffle=True)\ntesting_loader = torch.utils.data.DataLoader(val, batch_size=FLAGS[\"BATCH_SIZE\"], shuffle=True)\n\ndevice = xm.xla_device()","metadata":{"papermill":{"duration":0.027766,"end_time":"2023-11-04T12:40:23.286172","exception":false,"start_time":"2023-11-04T12:40:23.258406","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nb_trainable_parameters(model):\n        r\"\"\"\n        Returns the number of trainable parameters and number of all parameters in the model.\n        \"\"\"\n        trainable_params = 0\n        all_param = 0\n        for _, param in model.named_parameters():\n            num_params = param.numel()\n            # if using DS Zero 3 and the weights are initialized empty\n            if num_params == 0 and hasattr(param, \"ds_numel\"):\n                num_params = param.ds_numel\n\n            # Due to the design of 4bit linear layers from bitsandbytes\n            # one needs to multiply the number of parameters by 2 to get\n            # the correct number of parameters\n            if param.__class__.__name__ == \"Params4bit\":\n                num_params = num_params * 2\n\n            all_param += num_params\n            if param.requires_grad:\n                trainable_params += num_params\n\n        return trainable_params, all_param\ndef print_trainable_parameters(model):\n        \"\"\"\n        Prints the number of trainable parameters in the model.\n        \"\"\"\n        trainable_params, all_param = get_nb_trainable_parameters(model)\n\n        print(\n            f\"trainable params: {trainable_params:,d} || all params: {all_param:,d} || trainable%: {100 * trainable_params / all_param}\"\n        )\n\ncnt = 0\nfor param in model.parameters():\n    cnt += 1\n    param.requires_grad = False\n    if cnt > 0: # You can set this to a higher value to freeze parameters if your running out of memory.\n        param.requires_grad = True\nprint_trainable_parameters(model)\nconfig = AutoConfig.from_pretrained(MODEL)\nnum_devices = xr.global_runtime_device_count()\nmesh_shape = (1, num_devices, 1)\ndevice_ids = np.array(range(num_devices))\nmesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))\npartition_module(model, mesh) # After this, the model is sharded between cores but still has the same API as if it was on single device. Neat.","metadata":{"papermill":{"duration":29.992732,"end_time":"2023-11-04T12:40:53.298154","exception":false,"start_time":"2023-11-04T12:40:23.305422","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!export XLA_USE_BF16=1\n\ndef train(FLAGS):\n    num_iterations = int(FLAGS['NUM_STEPS'] / FLAGS['BATCH_SIZE'])\n    lr = 2e-5\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=FLAGS['NUM_STEPS'] * FLAGS['BATCH_SIZE'])\n    i = 0\n    total_loss = 0\n    for epoch in range(1, FLAGS['NUM_EPOCHS'] + 1):\n        model.train()\n        xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now()))\n        for step, batch in enumerate(training_loader):\n            optimizer.zero_grad()\n            input_ids = batch[\"input_ids\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            xs.mark_sharding(input_ids, mesh, (0, 1)) # Sharding inputs\n            xs.mark_sharding(labels, mesh, (0, 1))\n            outputs = model(input_ids=input_ids, labels=labels)\n            logits = outputs.logits\n            loss = outputs.loss\n            loss.requires_grad_()\n            loss.backward()\n            optimizer.step()\n            xm.mark_step()\n            if (step + 1) % FLAGS['LOGGING_STEPS'] == 0:\n                print(f'loss: {loss.item()}, time: {test_utils.now()}, step: {step}')\n \n            scheduler.step()\n            i += 1\n\n        model.eval()\n        total_loss = 0.0\n        total_steps = 0\n\n        with torch.no_grad():\n            for step, batch in enumerate(testing_loader):\n                input_ids = batch[\"input_ids\"].to(device)\n                labels = batch[\"labels\"].to(device)\n                xs.mark_sharding(input_ids, mesh, (0, 1))\n                xs.mark_sharding(labels, mesh, (0, 1))\n                outputs = model(input_ids=input_ids, labels=labels)\n                loss = outputs.loss\n                total_loss += loss.item()\n                total_steps += 1\n\n        average_loss = total_loss / total_steps\n        xm.master_print('Epoch {} test end {}, test loss={:.2f}'.format(epoch, test_utils.now(), average_loss))\n        xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))","metadata":{"papermill":{"duration":1.912133,"end_time":"2023-11-04T12:40:55.230144","exception":false,"start_time":"2023-11-04T12:40:53.318011","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(FLAGS) # I haven't tested the evaluation part in this notebook so hopefully it works. It really should","metadata":{"papermill":{"duration":2070.358248,"end_time":"2023-11-04T13:15:25.607979","exception":false,"start_time":"2023-11-04T12:40:55.249731","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf_write\") # Provide your own HF API token with write access\nlogin(hf_token)\nmodel = model.cpu()\nprint('now saving the model')\nmodel.push_to_hub(\n    SAVED_MODEL, \n    tokenizer=tokenizer,\n    safe_serialization=True,\n    private=True,\n    create_pr=True,\n    max_shard_size=\"2GB\", # Sharding isn't as important as before since hardware is better now but who cares anyway\n    )# We have to push the model to HF since there is not enough memory on disk. Download weights from there\ntokenizer.push_to_hub(\n    SAVED_MODEL,\n    private=True, \n    \n    )","metadata":{"papermill":{"duration":388.410448,"end_time":"2023-11-04T13:21:54.038795","exception":false,"start_time":"2023-11-04T13:15:25.628347","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}